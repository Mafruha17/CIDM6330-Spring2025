## üìò README.md ‚Äî Assignment 05: Full Django + Tests (with Optional AI Services)

### **West Texas A\&M University**

* **Semester:** Spring 2025
* **Course:** CIDM‚Äë6330‚Äë70 Software Engineering
* **Student:** Mafruha¬†Chowdhury

---

### üîó GitHub Repository

**Repository Link:** [CIDM6330‚ÄëSpring2025/Assignment05](https://github.com/Mafruha17/CIDM6330-Spring2025/tree/main/Assignment05)

* [ERD Diagram](https://github.com/Mafruha17/CIDM6330-Spring2025/blob/main/Assignment05/docs/edr.PNG)
* [Class Diagram](https://github.com/Mafruha17/CIDM6330-Spring2025/blob/main/Assignment05/docs/Class%20Diagram.png/edr.PNG)

---

## üìã Table of Contents

1. [Overview¬†& Objectives](#-overview--objectives)
2. [Tech¬†Stack](#-tech-stack)
3. [Architecture¬†& Patterns](#-architecture--patterns)
4. [Installation¬†& Setup](#Ô∏è-installation--setup)
5. [Docker, Redis, Celery](#-docker-redis-celery)
6. [API¬†Design](#-api-design)
7. [API Endpoints (Ninja¬†Routers)](#-api-endpoints-ninja-routers)
8. [Event‚ÄëDriven¬†Processing](#-event-driven-processing)
9. [Testing](#-testing)
10. [Behavior‚ÄëDriven Development (BDD)](#-behavior-driven-development-bdd-with-gherkin)
11. [Admin¬†Panel¬†Usage](#-admin-panel-usage)
12. [Troubleshooting](#Ô∏è-troubleshooting)
13. [Verification](#-verification)
14. [AI¬†Services¬†(Optional)](#-ai-services-optional)
15. [References](#-references)
16. [Conclusion](#-conclusion)
17. [Additional¬†Code¬†Files](#additional-code-files)

> *Sections after 14 were renumbered to accommodate the new optional AI component.*

---

## ü©∫ Overview & Objectives

*Unchanged from previous version.*

---

## üîå Tech Stack

| Component             | Purpose                          |
| --------------------- | -------------------------------- |
| `Django¬†5.1.7`        | Core framework                   |
| `django‚Äëninja`        | Modern API interface             |
| `celery¬†+¬†redis`      | Background task queue            |
| `PostgreSQL`          | Persistent DB (via Docker)       |
| `OpenAI/Azure¬†OpenAI` | External AI inference (optional) |
| `pytest/unittest`     | Testing & verification           |
| `Docker¬†Compose`      | Deployment                       |

---

## üß± Architecture & Patterns

*Unchanged, plus¬†AI diagram reference added in [AI¬†Services](#-ai-services-optional).*

---

## ‚öôÔ∏è Installation & Setup

```bash
# Clone the project
 git clone <REPO_URL>
 cd Assignment05

# Create a virtual environment
 python -m venv venv
 source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies (includes optional AI libs)
 pip install -r requirements.txt

# Run migrations
 python manage.py migrate

# Start server
 python manage.py runserver
```

> **AI‚ÄØkeys** ‚Äì if you enable the AI component, create a `.env` file with:
>
> ```bash
> OPENAI_API_KEY=sk-...
> OPENAI_MODEL=gpt-4o-mini  # or Azure deployment name
> ```

---

## üê≥ Docker, Redis, Celery

*Unchanged.*
Add `ai_services` environment variables to `django_app` section if the AI component is enabled.

---

## ‚ö° API Design

*Unchanged; see new AI endpoints below.*

---

## üîÄ API Endpoints (Ninja Routers)

*Existing routers unchanged.*

**AI Router (optional)** ‚Äî added if `ai_services` app is installed:

| Method | URL                     | Description                               |
| ------ | ----------------------- | ----------------------------------------- |
| `POST` | `/ai/summaries/`        | Summarize or translate clinical note text |
| `POST` | `/ai/device‚Äëanomalies/` | Detect anomalies in device telemetry      |

---

## üì° Event‚ÄëDriven Processing

*Unchanged.*
Optionally dispatch Celery tasks that call AI endpoints for heavy workloads.

---

## üß™ Testing

Add `tests/test_ai.py` covering summary and anomaly endpoints using mocked OpenAI responses.

---

## üß™ Behavior‚ÄëDriven Development (BDD) with Gherkin

*Unchanged.*
Include a new scenario for AI summary generation if desired.

---

## üßë‚Äçüíº Admin¬†Panel¬†Usage

*Unchanged.*

---

## üõ†Ô∏è Troubleshooting

| Issue                              | Fix                                                                |
| ---------------------------------- | ------------------------------------------------------------------ |
| `openai.error.AuthenticationError` | Verify `OPENAI_API_KEY` in env or secret store                     |
| High token cost                    | Set `temperature=0.2` and shorter prompts; monitor usage dashboard |

---

## ‚úÖ Verification

1. **Core¬†API** ‚Äì unchanged steps.
2. **AI Demo (optional)**

   ```bash
   curl -X POST http://localhost:8000/ai/summaries/ \
        -H "Content-Type: application/json" \
        -d '{"text": "Patient presents with ...", "language": "en"}'
   ```
3. Observe summarized output; check logs for token usage.

---

## ü§ñ AI Services (Optional)

### Why add AI?

* Provide concise, patient‚Äëfriendly summaries of clinical notes
* Flag anomalous vitals from wearables before provider review
* Demonstrate modern LLM integration for course extra credit

### Supported Providers

* **OpenAI API** (GPT-4, GPT-3.5)
* **Azure OpenAI Service** (deployments of OpenAI models in Azure)

### Other AI API Options

#### Text‚ÄëBased

* **AWS Comprehend Medical** ‚Äì Extract medical entities, PHI detection, and clinical summarization with HIPAA compliance.
* **Google Cloud Healthcare Natural Language API** ‚Äì Analyze and annotate clinical notes, identify medical terminology, and sentiment analysis.
* **Hugging Face Inference API** ‚Äì Use community models for summarization, translation, or fine‚Äëtuned clinical models.

#### Vision & Imaging

* **Azure Cognitive Services: Computer Vision** ‚Äì OCR, image classification, object detection, and medical image analysis via Custom Vision.
* **AWS Rekognition** ‚Äì Face detection, object and scene analysis, text in image, and video surveillance capabilities.
* **Google Cloud Vision API** ‚Äì Label detection, OCR, landmark detection, and AutoML Vision for custom models.
* **Hugging Face Transformers + PIL/OpenCV** ‚Äì On‚Äëdevice or server‚Äëside inference with vision‚Äëcapable models (e.g., DINO, CLIP) for anomaly detection in device images.

### Advanced Predictive Health‚ÄëAnalytics

Enhance proactive care by integrating predictive analytics on patient and device data:

* **Time‚ÄëSeries Forecasting**: Use frameworks like **Facebook¬†Prophet**, **TensorFlow**, or **Azure¬†Time¬†Series Insights** to project vital sign trends and detect deviations before they become critical.
* **Risk‚ÄëScoring Models**: Deploy custom or AutoML‚Äëtrained models on **Azure¬†ML**, **AWS¬†SageMaker**, or **Google¬†AI Platform** to compute health risk scores from EHR and sensor data.
* **Cohort Analytics**: Leverage **Azure Synapse** or **BigQuery** with integrated ML to identify at‚Äërisk patient groups and recommend interventions.

```python
# Example: call Azure ML REST scoring endpoint
import os, requests

def predict_risk(patient_features: dict) -> float:
    endpoint = os.getenv("AZURE_ML_ENDPOINT")
    api_key = os.getenv("AZURE_ML_KEY")
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {"data": [patient_features]}
    resp = requests.post(f"{endpoint}/score", json=payload, headers=headers)
    resp.raise_for_status()
    return resp.json()["predictedRiskScore"]
```

Use these analytics to trigger alerts, plan maintenance, or recommend follow‚Äëup care.

### Quick Start for Visual AI

1. Install SDK:

   ```bash
   pip install azure-cognitiveservices-vision-computervision  # for Azure CV
   pip install boto3                                           # for AWS Rekognition
   pip install google-cloud-vision                             # for GCP Vision
   ```
2. Configure credentials in `.env`:

   ```bash
   AZURE_CV_KEY=<key>
   AZURE_CV_ENDPOINT=<endpoint>
   AWS_ACCESS_KEY_ID=<key>
   AWS_SECRET_ACCESS_KEY=<secret>
   GOOGLE_APPLICATION_CREDENTIALS=/path/to/creds.json
   ```
3. Example usage (Azure Computer Vision):

   ```python
   from azure.cognitiveservices.vision.computervision import ComputerVisionClient
   from msrest.authentication import CognitiveServicesCredentials

   cv_client = ComputerVisionClient(
       os.getenv("AZURE_CV_ENDPOINT"),
       CognitiveServicesCredentials(os.getenv("AZURE_CV_KEY"))
   )

   def analyze_image(url: str):
       features = cv_client.analyze_image(url, ["Tags", "Objects", "OCR"])
       return {"tags": [t.name for t in features.tags], "text": features.ocr.read_results}
   ```

---

### Why add AI?

* Provide concise, patient‚Äëfriendly summaries of clinical notes
* Flag anomalous vitals from wearables before provider review
* Demonstrate modern LLM integration for course extra credit

### Quick¬†Start

1. `pip install openai` (already in requirements)
2. Export `OPENAI_API_KEY`.
3. Add `"ai_services"` to `INSTALLED_APPS`.
4. Include router in `mainapp/api/__init__.py`:

   ```python
   from ai_services.api_ai import router as ai_router
   api.add_router("/ai/", ai_router, tags=["AI"])
   ```

### Minimal Service Implementation

```python
# ai_services/services.py
import openai
from django.conf import settings
openai.api_key = settings.OPENAI_API_KEY


def summarize_note(text: str, lang: str = "en") -> str:
    prompt = (f"Summarize the clinical note below in plain {lang}, 3 sentences, no jargon:\n\n{text}")
    resp = openai.ChatCompletion.create(
        model=settings.OPENAI_MODEL,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
        max_tokens=200,
    )
    return resp.choices[0].message.content.strip()
```

### Security & Compliance

* **De‚Äëidentify** PHI before outbound requests.
* Use Azure¬†OpenAI with HIPAA eligibility or sign BAA with provider.
* Log `user_id`, endpoint, prompt tokens, and response IDs for auditing.

---

## üìô References

*Added*

* OpenAI Python SDK [https://github.com/openai/openai-python](https://github.com/openai/openai-python)
* Azure¬†OpenAI Service HIPAA Overview

---

## üåü Conclusion

This project demonstrates a robust Django backend with optional AI enhancement, showcasing:

* Clean API design (Django¬†Ninja)
* Message‚Äëdriven architecture (Celery¬†+¬†Redis)
* PostgreSQL persistence
* Modular Repository Pattern
* **AI Services for clinical summarization & device anomaly detection**
* Fully tested backend with zero UI

Ready for further expansion into billing, appointment scheduling, or advanced predictive health‚Äëanalytics.

---

## Additional Code Files

See full structure and links in [üìÅ View¬†Project¬†Files](https://github.com/Mafruha17/CIDM6330-Spring2025/tree/main/Assignment05)

---

### üõ†Ô∏è Quick¬†Setup

```bash
# 1Ô∏è‚É£  From the Assignment05 root directory
python -m venv venv          # or poetry env use python3.11
source venv/bin/activate      # Windows: venv\Scripts\activate

# 2Ô∏è‚É£  Install all project dependencies
pip install -r requirements.txt

# ‚Ä¶or install just the OpenAI SDK individually if you‚Äôre experimenting:
pip install openai

# 3Ô∏è‚É£  Run the local stack
python manage.py migrate
python manage.py runserver 0.0.0.0:8000
```

> **Why here?**¬†Running `pip install ‚Ä¶` inside the *Assignment05* directory ensures the package is installed into the same virtual¬†environment that your Django & FastAPI apps use. Location on disk doesn‚Äôt matter as long as the venv is active, but staying at the project root keeps your dependency tree tidy and your `requirements.txt` reproducible.

Add **`openai==1.*`** to `requirements.txt`, commit, and push so CI/CD and teammates get the same environment.

---

**Suggesting PowerShell script**

It looks like the user wants to run the test in a PowerShell script, perhaps using Python code in it. I could provide an example using a here-string or OpenAI CLI, but they're asking specifically for PowerShell. So, I might suggest embedding Python code or calling it directly with `-c`. A good option is a `.ps1` script like this:

```
$env:OPENAI_API_KEY = 'sk-...'
$script = @"
import openai
from django.conf import settings
import os, django
...
"@
python - <<EOF
... EOF
```


Thought for 5 seconds


Here‚Äôs a tiny PowerShell script you can drop into your project root (e.g. call it **`test_openai.ps1`**) to smoke-test your OpenAI integration from PowerShell:

```powershell
# test_openai.ps1
# 1) Make sure you‚Äôre in Assignment05/ and your venv is active:
#    PS> .\venv\Scripts\Activate.ps1
#
# 2) Then just run:
#    PS> .\test_openai.ps1

# Build the Python snippet as a here-string
$pythonCode = @"
import os
import django
from django.conf import settings

# bootstrap Django so settings.py is loaded
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
os.chdir(BASE_DIR)       # ensure manage.py is on the CWD
django.setup()

import openai
openai.api_key = settings.OPENAI_API_KEY
model = settings.OPENAI_MODEL

# fire off a quick prompt
resp = openai.ChatCompletion.create(
    model=model,
    messages=[{"role": "user", "content": "What is 2+2?"}],
    max_tokens=5,
)

print(">> LLM answer:", resp.choices[0].message.content.strip())
"@

# Pipe it into python
$pythonCode | python
```

### How it works

1. **Here-string** (`@"‚Ä¶@"`) holds your Python code.
2. Piping (`| python`) feeds it to Python‚Äôs STDIN.
3. Inside the snippet, we:

   * `os.chdir(BASE_DIR)` so that `django.setup()` finds your `manage.py` and `djconfig/settings.py`
   * Call the same OpenAI SDK code you‚Äôll eventually use in `ai_services`.

#### Running it

```powershell
PS> cd Assignment05
PS> .\venv\Scripts\Activate.ps1
(venv) PS> .\test_openai.ps1
>> LLM answer: 4
```

If you see a ‚Äú4‚Äù (or similar), your `.env`‚Üí`django-environ`‚ÜíOpenAI pipeline is fully wired up.


---
# test_openai.ps1
# 1) Make sure you‚Äôre in Assignment05/ and your venv is active:
#    PS> .\venv\Scripts\Activate.ps1
#
# 2) Then just run:
#    PS> .\test_openai.ps1

# Build the Python snippet as a here-string
$pythonCode = @"
import os
import django
from django.conf import settings

# bootstrap Django so settings.py is loaded
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
os.chdir(BASE_DIR)       # ensure manage.py is on the CWD
django.setup()

import openai
openai.api_key = settings.OPENAI_API_KEY
model = settings.OPENAI_MODEL

# fire off a quick prompt
resp = openai.ChatCompletion.create(
    model=model,
    messages=[{"role": "user", "content": "What is 2+2?"}],
    max_tokens=5,
)

print(">> LLM answer:", resp.choices[0].message.content.strip())
"@

# Pipe it into python
$pythonCode | python

---